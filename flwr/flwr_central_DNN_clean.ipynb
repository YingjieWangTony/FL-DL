{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "bANoPbqWGWRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fe360f-4684-450e-e870-71414f5f63e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import Metrics\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ043aExGXXo",
        "outputId": "7cb0548c-f17f-4cc2-ee1f-4788b65940c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 1.13.1+cu116 and Flower 1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n"
      ],
      "metadata": {
        "id": "CLae2PQzLd-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "time_step = 48\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "aEGaHFgxWErx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open ('House_30.txt', 'r') as reader:\n",
        "  for line in reader:\n",
        "    stripped_line = line.strip().split()\n",
        "    data.append(stripped_line)\n",
        "\n",
        "tem = [x[0] for x in data]\n",
        "houses = list(set(tem))\n",
        "\n",
        "date = []\n",
        "consumption = []\n",
        "for i in houses:\n",
        "  date.append([float(x[1]) for x in data if x[0]==i])\n",
        "  consumption.append([float(x[2]) for x in data if x[0]==i])    "
      ],
      "metadata": {
        "id": "6_GLqxcrFe-B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_label(data, time_step):\n",
        "  x_nest, y_nest = [], []\n",
        "  for j in range(len(data)):\n",
        "    x_data, y_data = [], []\n",
        "    for i in range(len(data[j]) - time_step):\n",
        "      x = data[j][i: (i + time_step)]\n",
        "      x_data.append(x)\n",
        "      y = [data[j][i + time_step]]\n",
        "      y_data.append(y)\n",
        "\n",
        "    #x_data = np.array(x_data)[:, :, np.newaxis]\n",
        "    x_data = np.array(x_data)[:, :]\n",
        "    #x_data = np.array(x_data)[:, np.newaxis, :]\n",
        "    x_nest.append(x_data)\n",
        "    y_nest.append(y_data)\n",
        "  x_nest = np.array(x_nest)\n",
        "  y_nest = np.array(y_nest)\n",
        "  return x_nest, y_nest\n",
        "# 可能要去掉x的最后一个维度 从（48，1）变为（48）"
      ],
      "metadata": {
        "id": "lFh5oiv0QHXG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, labels = create_label(consumption, time_step)\n"
      ],
      "metadata": {
        "id": "E50GczgkSAoF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.float32(input)\n",
        "labels = np.float32(labels)\n"
      ],
      "metadata": {
        "id": "YUlLivPStSy0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset"
      ],
      "metadata": {
        "id": "RN0xa70WooMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义GetLoader类，继承Dataset方法，并重写__getitem__()和__len__()方法\n",
        "class GetLoader(torch.utils.data.Dataset):\n",
        "\t# 初始化函数，得到数据\n",
        "    def __init__(self, data_root, data_label):\n",
        "        self.data = data_root\n",
        "        self.label = data_label\n",
        "    # index是根据batchsize划分数据后得到的索引，最后将data和对应的labels进行一起返回\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        labels = self.label[index]\n",
        "        return data, labels\n",
        "    # 该函数返回数据大小长度，目的是DataLoader方便划分，如果不知道大小，DataLoader会一脸懵逼\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "55XqPaqDiGq1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(input[0])\n",
        "val = int(0.7*length)\n",
        "test = int(0.9*length)\n",
        "trainloaders = []\n",
        "valloaders = []\n",
        "testloaders = []\n",
        "\n",
        "def load_datasets(input, labels):\n",
        "\n",
        "  Xtrain_raw = [x[0: val] for x in input]\n",
        "  Xval_raw = [x[val: test] for x in input]\n",
        "  Xtest_raw = [x[test: ] for x in input]\n",
        "\n",
        "  Ytrain_raw = [x[0: val] for x in labels]\n",
        "  Yval_raw = [x[val: test] for x in labels]\n",
        "  Ytest_raw = [x[test: ] for x in labels]\n",
        "\n",
        "  for i in range(30):\n",
        "    ds_train = GetLoader(Xtrain_raw[i], Ytrain_raw[i])\n",
        "    trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True))\n",
        "    ds_val = GetLoader(Xval_raw[i], Yval_raw[i])\n",
        "    valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE, drop_last=True))\n",
        "    ds_test= GetLoader(Xtest_raw[i], Ytest_raw[i])\n",
        "    testloaders.append(DataLoader(ds_test, batch_size=BATCH_SIZE, drop_last=True))\n",
        "\n",
        "  return trainloaders, valloaders, testloaders\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EpQp0W7zxZTP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloaders, valloaders, testloaders = load_datasets(input, labels)"
      ],
      "metadata": {
        "id": "xgeKNAg80aTF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "pVfo0GkH1fGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "KlFemn7iWd8m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        act = nn.Sigmoid\n",
        "        self.body = nn.Sequential(\n",
        "            nn.Linear(48, 48),\n",
        "            act(),\n",
        "            nn.Linear(48, 48),\n",
        "            act(),\n",
        "            nn.Linear(48, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = self.body(x)\n",
        "        return out\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "net = DNN().to(DEVICE)\n"
      ],
      "metadata": {
        "id": "chi_F7TF1hxn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for x, y in trainloader:\n",
        "            \n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #x = x.unsqueeze(0)\n",
        "            outputs = net(x)\n",
        "            loss = criterion(net(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss\n",
        "           \n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}\") \n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            outputs = net(x)\n",
        "            loss += criterion(outputs, y).item()\n",
        "\n",
        "    loss /= len(testloader.dataset)\n",
        "   \n",
        "    return loss "
      ],
      "metadata": {
        "id": "b-mYJ2P8WIUe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### central test"
      ],
      "metadata": {
        "id": "BB6uIeGTgLMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(trainloaders[0]))"
      ],
      "metadata": {
        "id": "BnoFs1KRbUzT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = DNN().to(DEVICE)\n",
        "client_n = 30\n",
        "MSE_cen = [0 for i in range(client_n)]\n",
        "epoch = 300\n",
        "\n",
        "for i in range(client_n):\n",
        "  trainloader = trainloaders[i]\n",
        "  testloader = testloaders[i]\n",
        "  train(net, trainloader, epoch)\n",
        "  loss = test(net, testloader)\n",
        "  print(f\"client {i}: centralized model loss {loss}\")\n",
        "  MSE_cen[i] = loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XldM5rm0X52f",
        "outputId": "7811cf53-d790-4516-8caa-d9d7ec1c3b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 0: centralized model loss 0.00019022170291064638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "testloader = testloaders[0]\n",
        "\n",
        "\n",
        "net = DNN().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(net, trainloader, 300)\n",
        "    loss = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}\")\n",
        "\n",
        "loss = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVJaWgOLXgpe",
        "outputId": "42d52f1e-942c-4d74-9fed-b4744a519679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: validation loss 0.004740860300121185\n",
            "Epoch 2: validation loss 0.004740860321881058\n",
            "Epoch 3: validation loss 0.0047408603291343495\n",
            "Epoch 4: validation loss 0.004740860362499488\n",
            "Epoch 5: validation loss 0.004740860347992906\n",
            "Final test set performance:\n",
            "\tloss 0.003996639648841178\n"
          ]
        }
      ]
    }
  ]
}