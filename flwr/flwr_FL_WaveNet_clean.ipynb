{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "bANoPbqWGWRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2f938e-5116-4754-ff4e-5fde91da5a38"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from flwr.common import Metrics\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ043aExGXXo",
        "outputId": "db2cdce4-f85e-4ace-e771-9e65c0b5f367"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 1.13.1+cu116 and Flower 1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n"
      ],
      "metadata": {
        "id": "CLae2PQzLd-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "time_step = 48\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "aEGaHFgxWErx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "with open ('House_30.txt', 'r') as reader:\n",
        "  for line in reader:\n",
        "    stripped_line = line.strip().split()\n",
        "    data.append(stripped_line)\n",
        "\n",
        "tem = [x[0] for x in data]\n",
        "houses = list(set(tem))\n",
        "\n",
        "date = []\n",
        "consumption = []\n",
        "for i in houses:\n",
        "  date.append([float(x[1]) for x in data if x[0]==i])\n",
        "  consumption.append([float(x[2]) for x in data if x[0]==i])    "
      ],
      "metadata": {
        "id": "6_GLqxcrFe-B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_label(data, time_step):\n",
        "  x_nest, y_nest = [], []\n",
        "  for j in range(len(data)):\n",
        "    x_data, y_data = [], []\n",
        "    for i in range(len(data[j]) - time_step):\n",
        "      x = data[j][i: (i + time_step)]\n",
        "      x_data.append(x)\n",
        "      y = [data[j][i + time_step]]\n",
        "      y_data.append(y)\n",
        "\n",
        "    #x_data = np.array(x_data)[:, :, np.newaxis]\n",
        "    x_data = np.array(x_data)[:, :]\n",
        "    #x_data = np.array(x_data)[:, np.newaxis, :]\n",
        "    x_nest.append(x_data)\n",
        "    y_nest.append(y_data)\n",
        "  x_nest = np.array(x_nest)\n",
        "  y_nest = np.array(y_nest)\n",
        "  return x_nest, y_nest\n",
        "# 可能要去掉x的最后一个维度 从（48，1）变为（48）"
      ],
      "metadata": {
        "id": "lFh5oiv0QHXG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input, labels = create_label(consumption, time_step)\n"
      ],
      "metadata": {
        "id": "E50GczgkSAoF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.float32(input)\n",
        "labels = np.float32(labels)\n"
      ],
      "metadata": {
        "id": "YUlLivPStSy0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dataset"
      ],
      "metadata": {
        "id": "RN0xa70WooMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义GetLoader类，继承Dataset方法，并重写__getitem__()和__len__()方法\n",
        "class GetLoader(torch.utils.data.Dataset):\n",
        "\t# 初始化函数，得到数据\n",
        "    def __init__(self, data_root, data_label):\n",
        "        self.data = data_root\n",
        "        self.label = data_label\n",
        "    # index是根据batchsize划分数据后得到的索引，最后将data和对应的labels进行一起返回\n",
        "    def __getitem__(self, index):\n",
        "        data = self.data[index]\n",
        "        labels = self.label[index]\n",
        "        return data, labels\n",
        "    # 该函数返回数据大小长度，目的是DataLoader方便划分，如果不知道大小，DataLoader会一脸懵逼\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n"
      ],
      "metadata": {
        "id": "55XqPaqDiGq1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(input[0])\n",
        "val = int(0.7*length)\n",
        "test = int(0.9*length)\n",
        "trainloaders = []\n",
        "valloaders = []\n",
        "testloaders = []\n",
        "\n",
        "def load_datasets(input, labels):\n",
        "\n",
        "  Xtrain_raw = [x[0: val] for x in input]\n",
        "  Xval_raw = [x[val: test] for x in input]\n",
        "  Xtest_raw = [x[test: ] for x in input]\n",
        "\n",
        "  Ytrain_raw = [x[0: val] for x in labels]\n",
        "  Yval_raw = [x[val: test] for x in labels]\n",
        "  Ytest_raw = [x[test: ] for x in labels]\n",
        "\n",
        "  for i in range(30):\n",
        "    ds_train = GetLoader(Xtrain_raw[i], Ytrain_raw[i])\n",
        "    trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True, drop_last=True))\n",
        "    ds_val = GetLoader(Xval_raw[i], Yval_raw[i])\n",
        "    valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE, drop_last=True))\n",
        "    ds_test= GetLoader(Xtest_raw[i], Ytest_raw[i])\n",
        "    testloaders.append(DataLoader(ds_test, batch_size=BATCH_SIZE, drop_last=True))\n",
        "\n",
        "  return trainloaders, valloaders, testloaders\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EpQp0W7zxZTP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloaders, valloaders, testloaders = load_datasets(input, labels)"
      ],
      "metadata": {
        "id": "xgeKNAg80aTF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "pVfo0GkH1fGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "KlFemn7iWd8m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CasualDilatedConv1D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1D = nn.Conv1d(in_channels, out_channels, kernel_size, dilation=dilation, bias=False, padding='same')\n",
        "        self.ignoreOutIndex = (kernel_size - 1) * dilation\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv1D(x)[..., :-self.ignoreOutIndex]\n",
        "\n",
        "\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1) # dim=2\n",
        "        self.conv1d = nn.Conv1d(in_channels, in_channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, skipConnection):\n",
        "        # as b c outputsize -> skipConnection size\n",
        "        out = torch.mean(skipConnection, dim=0)\n",
        "\n",
        "        for i in range(2):\n",
        "            out = self.relu(out)\n",
        "            out = self.conv1d(out)\n",
        "        return self.softmax(out)\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, res_channels, skip_channels, kernel_size, dilation):\n",
        "        super().__init__()\n",
        "        self.casualDilatedConv1D = CasualDilatedConv1D(res_channels, res_channels, kernel_size, dilation=dilation)\n",
        "        self.resConv1D = nn.Conv1d(res_channels, res_channels, kernel_size=1)\n",
        "        self.skipConv1D = nn.Conv1d(res_channels, skip_channels, kernel_size=1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputX, skipSize):\n",
        "        x = self.casualDilatedConv1D(inputX)\n",
        "        x1 = self.tanh(x)\n",
        "        x2 = self.sigmoid(x)\n",
        "        x = x1 * x2\n",
        "        resOutput = self.resConv1D(x)\n",
        "        resOutput = resOutput + inputX[..., -resOutput.size(1):] # resOutput.size(2)\n",
        "        skipOutput = self.skipConv1D(x)\n",
        "        skipOutput = skipOutput[..., -skipSize:]\n",
        "        return resOutput, skipOutput\n",
        "\n",
        "\n",
        "class StackOfResBlocks(nn.Module):\n",
        "\n",
        "    def __init__(self, stack_size, layer_size, res_channels, skip_channels, kernel_size):\n",
        "        super().__init__()\n",
        "        buildDilationFunc = np.vectorize(self.buildDilation)\n",
        "        dilations = buildDilationFunc(stack_size, layer_size)\n",
        "        self.resBlocks = []\n",
        "        for s,dilationPerStack in enumerate(dilations):\n",
        "            for l,dilation in enumerate(dilationPerStack):\n",
        "                resBlock=ResBlock(res_channels, skip_channels, kernel_size, dilation)\n",
        "                self.add_module(f'resBlock_{s}_{l}', resBlock) # Add modules manually\n",
        "                self.resBlocks.append(resBlock)\n",
        "\n",
        "    def buildDilation(self, stack_size, layer_size):\n",
        "        # stack1=[1,2,4,8,16,...512]\n",
        "        dilationsForAllStacks = []\n",
        "        for stack in range(stack_size):\n",
        "            dilations = []\n",
        "            for layer in range(layer_size):\n",
        "                dilations.append(2 ** layer)\n",
        "            dilationsForAllStacks.append(dilations)\n",
        "        return dilationsForAllStacks\n",
        "\n",
        "    def forward(self, x, skipSize):\n",
        "        resOutput = x\n",
        "        skipOutputs = []\n",
        "        for resBlock in self.resBlocks:\n",
        "            resOutput, skipOutput = resBlock(resOutput, skipSize)\n",
        "            skipOutputs.append(skipOutput)\n",
        "        return resOutput, torch.stack(skipOutputs)\n",
        "\n",
        "\n",
        "class WaveNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stack_size, layer_size):\n",
        "        super().__init__()\n",
        "        self.stack_size = stack_size\n",
        "        self.layer_size = layer_size\n",
        "        self.kernel_size = kernel_size\n",
        "        self.casualConv1D = CasualDilatedConv1D(in_channels, in_channels, kernel_size, dilation=1)\n",
        "        self.stackResBlock = StackOfResBlocks(self.stack_size, self.layer_size, in_channels, out_channels, kernel_size)\n",
        "        self.denseLayer = DenseLayer(out_channels)\n",
        "\n",
        "\n",
        "    def calculateReceptiveField(self):\n",
        "        return np.sum([(self.kernel_size - 1) * (2 ** l) for l in range(self.layer_size)] * self.stack_size)\n",
        "\n",
        "    def calculateOutputSize(self, x):\n",
        "        return int(x.size(1)) - self.calculateReceptiveField() # x.size(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: b c t -> input data size\n",
        "        x = self.casualConv1D(x)\n",
        "        skipSize = self.calculateOutputSize(x)\n",
        "        _, skipConnections = self.stackResBlock(x, skipSize)\n",
        "        dense=self.denseLayer(skipConnections)\n",
        "        return dense\n",
        "    \n",
        "class WaveNetPre(nn.Module):\n",
        "    def __init__(self,seqLen,output_size):\n",
        "        super().__init__()\n",
        "        self.output_size=output_size\n",
        "        self.wavenet=WaveNet(32,32,2,3,4) # 1 1 2 3 4\n",
        "      #  self.liner=nn.Linear(2,output_size) # seqLen-self.wavenet.calculateReceptiveField()\n",
        "        self.softmax=nn.Softmax(-1)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x=self.wavenet(x)\n",
        "      #  x=self.liner(x)\n",
        "        return self.softmax(x)"
      ],
      "metadata": {
        "id": "rWIw0O5nR7bc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for x, y in trainloader:\n",
        "            \n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            #x = x.unsqueeze(0)\n",
        "            outputs = net(x)\n",
        "            loss = criterion(net(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss\n",
        "           \n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}\") \n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            outputs = net(x)\n",
        "            loss += criterion(outputs, y).item()\n",
        "\n",
        "    loss /= len(testloader.dataset)\n",
        "   \n",
        "    return loss "
      ],
      "metadata": {
        "id": "b-mYJ2P8WIUe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### central test"
      ],
      "metadata": {
        "id": "BB6uIeGTgLMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(trainloaders[0]))"
      ],
      "metadata": {
        "id": "BnoFs1KRbUzT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.unsqueeze(0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a34JmOpkpNXj",
        "outputId": "cf4e3dfd-1606-4270-cf69-f88a16b1cae2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 48])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "testloader = testloaders[0]\n",
        "\n",
        "net = WaveNetPre(48,1).to(DEVICE)\n",
        "#net = WaveNet().to(DEVICE)\n",
        "#net = CNN().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "    train(net, trainloader, 1)\n",
        "    loss = test(net, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}\")\n",
        "\n",
        "loss = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVJaWgOLXgpe",
        "outputId": "eb6c2991-d67e-46cd-c074-0078711ead71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
            "  return F.conv1d(input, weight, bias, self.stride,\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: validation loss 0.005170582816863543\n",
            "Epoch 2: validation loss 0.005170582798004986\n",
            "Epoch 3: validation loss 0.005170582780597088\n",
            "Epoch 4: validation loss 0.00517058281106091\n",
            "Epoch 5: validation loss 0.005170582816863543\n",
            "Final test set performance:\n",
            "\tloss 0.005210138094318433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVu1Sc81gJA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FL"
      ],
      "metadata": {
        "id": "b2YggcpRgPB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "W1p2DJnRgRAW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, valloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(0)}\n",
        "\n"
      ],
      "metadata": {
        "id": "ez9P_QZLhiu1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "    net = WaveNetPre(48,1).to(DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "\n",
        "    # Create a  single Flower client representing a single organization\n",
        "    return FlowerClient(net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "P_TsTweQim4j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLIENTS = 30"
      ],
      "metadata": {
        "id": "RO_7kHysjbAL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwR-YZWuUT-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "        fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "        fraction_evaluate=0.3,  # Sample 50% of available clients for evaluation\n",
        "        min_fit_clients=10,  # Never sample less than 10 clients for training\n",
        "        min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
        "        min_available_clients=10,  # Wait until all 10 clients are available\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "  client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5), #10\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "id": "7CCC8WGbjNLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247ab486-443d-43ef-c74f-61ba39727ac9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-03-01 08:34:16,942 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-03-01 08:34:18,842\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "INFO flwr 2023-03-01 08:34:20,624 | app.py:179 | Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7911577191.0, 'object_store_memory': 3955788595.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:172.28.0.12': 1.0, 'CPU': 2.0, 'memory': 7911577191.0, 'object_store_memory': 3955788595.0}\n",
            "INFO flwr 2023-03-01 08:34:20,639 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-03-01 08:34:20,651 | server.py:270 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "INFO flwr 2023-03-01 08:34:22,908 | server.py:274 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-03-01 08:34:22,915 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-03-01 08:34:22,919 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-03-01 08:34:22,922 | server.py:215 | fit_round 1: strategy sampled 30 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 30 clients (out of 30)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:172: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m   return F.conv1d(input, weight, bias, self.stride,\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1415)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:172: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:199.)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m   return F.conv1d(input, weight, bias, self.stride,\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m /usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=1416)\u001b[0m   return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 2596 MiB, 40 objects, write throughput 179 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
            "DEBUG flwr 2023-03-01 08:39:46,303 | server.py:229 | fit_round 1 received 30 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 30 results and 0 failures\n",
            "WARNING flwr 2023-03-01 08:39:47,017 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-03-01 08:39:47,023 | server.py:165 | evaluate_round 1: strategy sampled 9 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 9 clients (out of 30)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 4543 MiB, 66 objects, write throughput 191 MiB/s.\n",
            "DEBUG flwr 2023-03-01 08:40:00,788 | server.py:179 | evaluate_round 1 received 9 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 9 results and 0 failures\n",
            "WARNING flwr 2023-03-01 08:40:00,790 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-03-01 08:40:00,801 | server.py:215 | fit_round 2: strategy sampled 30 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 30 clients (out of 30)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 8309 MiB, 124 objects, write throughput 196 MiB/s.\n",
            "DEBUG flwr 2023-03-01 08:45:27,214 | server.py:229 | fit_round 2 received 30 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 30 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:45:27,937 | server.py:165 | evaluate_round 2: strategy sampled 9 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 9 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 08:45:40,269 | server.py:179 | evaluate_round 2 received 9 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:45:40,276 | server.py:215 | fit_round 3: strategy sampled 30 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 30 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 08:51:17,906 | server.py:229 | fit_round 3 received 30 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 30 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:51:18,582 | server.py:165 | evaluate_round 3: strategy sampled 9 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 9 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 08:51:29,833 | server.py:179 | evaluate_round 3 received 9 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:51:29,836 | server.py:215 | fit_round 4: strategy sampled 30 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 30 clients (out of 30)\n",
            "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 16488 MiB, 246 objects, write throughput 204 MiB/s.\n",
            "DEBUG flwr 2023-03-01 08:57:05,983 | server.py:229 | fit_round 4 received 30 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 30 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:57:06,647 | server.py:165 | evaluate_round 4: strategy sampled 9 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 9 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 08:57:19,959 | server.py:179 | evaluate_round 4 received 9 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 9 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 08:57:19,963 | server.py:215 | fit_round 5: strategy sampled 30 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 30 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 09:03:00,348 | server.py:229 | fit_round 5 received 30 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 30 results and 0 failures\n",
            "DEBUG flwr 2023-03-01 09:03:01,029 | server.py:165 | evaluate_round 5: strategy sampled 9 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 9 clients (out of 30)\n",
            "DEBUG flwr 2023-03-01 09:03:13,330 | server.py:179 | evaluate_round 5 received 9 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 9 results and 0 failures\n",
            "INFO flwr 2023-03-01 09:03:13,334 | server.py:144 | FL finished in 1730.411986375\n",
            "INFO:flwr:FL finished in 1730.411986375\n",
            "INFO flwr 2023-03-01 09:03:13,339 | app.py:202 | app_fit: losses_distributed [(1, 0.004836346873192792), (2, 0.004782465589256921), (3, 0.0046594065878225645), (4, 0.004905144954322685), (5, 0.004861670817345556)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.004836346873192792), (2, 0.004782465589256921), (3, 0.0046594065878225645), (4, 0.004905144954322685), (5, 0.004861670817345556)]\n",
            "INFO flwr 2023-03-01 09:03:13,342 | app.py:203 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2023-03-01 09:03:13,344 | app.py:204 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-03-01 09:03:13,347 | app.py:205 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.004836346873192792\n",
              "\tround 2: 0.004782465589256921\n",
              "\tround 3: 0.0046594065878225645\n",
              "\tround 4: 0.004905144954322685\n",
              "\tround 5: 0.004861670817345556"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}